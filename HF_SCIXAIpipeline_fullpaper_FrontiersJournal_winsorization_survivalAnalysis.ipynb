{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dff19bef-765e-466c-b0b0-edc780da3555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import general libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Import libraries useful for building the pipeline and join their branches\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "#import modules created for data preparation phase\n",
    "import my_utils\n",
    "import missing_val_imput\n",
    "import feature_select\n",
    "import preprocessing\n",
    "import adhoc_transf\n",
    "\n",
    "#import libraries for data preparation phase\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, StandardScaler\n",
    "\n",
    "\n",
    "#import libraries from modelling phase\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#to save model fit with GridSearchCV and avoid longer waits\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "285dd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libs for explainability\n",
    "from model import SurvSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2325bcdb-2ff5-4297-be9f-f3d3b81f1c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15.6.23 The target feature is dealing with death event and time\n",
    "#Loading the dataset\n",
    "path_data=r'heart_failure_clinical_records_dataset.csv'\n",
    "\n",
    "df=pd.read_csv(path_data)\n",
    "df.head()\n",
    "\n",
    "#%%Characterizing the data set\n",
    "target_features=['DEATH_EVENT','time']\n",
    "numerical_feats=['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium']\n",
    "nominal_feats=['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']\n",
    "ordinal_feats=[]\n",
    "\n",
    "len_numerical_feats=len(numerical_feats)\n",
    "len_nominal_feats=len(nominal_feats)\n",
    "len_ordinal_feats=len(ordinal_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29181f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1203.8</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.1</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age anaemia  creatinine_phosphokinase diabetes  ejection_fraction  \\\n",
       "0  75.0       0                     582.0        0                 20   \n",
       "1  55.0       0                    1203.8        0                 38   \n",
       "2  65.0       0                     146.0        0                 20   \n",
       "3  50.0       1                     111.0        0                 20   \n",
       "4  65.0       1                     160.0        1                 20   \n",
       "\n",
       "  high_blood_pressure  platelets  serum_creatinine  serum_sodium sex smoking  \\\n",
       "0                   1  265000.00               1.9         130.0   1       0   \n",
       "1                   0  263358.03               1.1         136.0   1       0   \n",
       "2                   0  162000.00               1.3         129.0   1       1   \n",
       "3                   0  210000.00               1.9         137.0   1       0   \n",
       "4                   0  327000.00               2.1         116.0   0       0   \n",
       "\n",
       "   time  DEATH_EVENT  \n",
       "0     4            1  \n",
       "1     6            1  \n",
       "2     7            1  \n",
       "3     7            1  \n",
       "4     8            1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35107b77",
   "metadata": {},
   "source": [
    "#Step 1 Solving wrong characters of dataset\n",
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3eca40b-db98-4e6b-886f-414985ba67c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>>Calling init() from ageRounder\n",
      "\n",
      ">>>>>>>>Calling fit() from ageRounder\n",
      "\n",
      ">>>>>>>>Calling transform() from ageRounder\n",
      "\n",
      ">>>>>>>>Calling rounder\n",
      "\n",
      ">>>>>>>>Calling init() from Numeric_Cast_Column\n",
      "\n",
      ">>>>>>>>Calling fit() from Numeric_Cast_Column\n",
      "\n",
      ">>>>>>>>Calling transform() from Numeric_Cast_Column\n",
      "\n",
      ">>>>>>>>Calling init() from Category_Cast_Column\n",
      "\n",
      ">>>>>>>>Calling fit() from Category_Cast_Column\n",
      "\n",
      ">>>>>>>>Calling transform() from Category_Cast_Column\n",
      "\n",
      ">>>>>>>>Calling init() from Category_Cast_Column\n",
      "\n",
      ">>>>>>>>Calling fit() from Category_Cast_Column\n",
      "\n",
      ">>>>>>>>Calling transform() from Category_Cast_Column\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "###################################################################################################################\n",
    "#Step 1 Solving wrong characters of dataset\n",
    "###################################################################################################################\n",
    "#Set column id as index\n",
    "\n",
    "\n",
    "# CKD case does only have misspellingCorrector\n",
    "# df_content_solver=Pipeline([('fx1', misspellingCorrector()),\n",
    "#                             ('fx2',function2()),\n",
    "#                             ('fx3',function3())\n",
    "# ])\n",
    "\n",
    "#%%\n",
    "df=adhoc_transf.ageRounder().fit_transform(df)\n",
    "#my_utils.df_values(df)\n",
    "\n",
    "#%%Performing numeric cast for numerical features\n",
    "df.loc[:,numerical_feats]=adhoc_transf.Numeric_Cast_Column().fit_transform(df.loc[:,numerical_feats])\n",
    "df[numerical_feats].dtypes\n",
    "\n",
    "\n",
    "#%%Performing category cast for nominal features\n",
    "df.loc[:,nominal_feats]=adhoc_transf.Category_Cast_Column().fit_transform(df.loc[:,nominal_feats])\n",
    "df[nominal_feats].dtypes\n",
    "\n",
    "#%%Performing category cast for ordinal features\n",
    "df.loc[:,ordinal_feats]=adhoc_transf.Category_Cast_Column().fit_transform(df.loc[:,ordinal_feats])\n",
    "df[ordinal_feats].dtypes\n",
    "\n",
    "#%%\n",
    "###################################################################################################################\n",
    "##Step 1.1 Winsorization strategies to set the outliers to the values of 10 and 90 percentiles\n",
    "####################################################################\n",
    "\n",
    "\n",
    "def winsorize_percentiles(df, columns, lower_percentile, upper_percentile):\n",
    "    for column in columns:\n",
    "        lower_limit = df[column].quantile(lower_percentile/100)\n",
    "        upper_limit = df[column].quantile(upper_percentile/100)\n",
    "        df[column] = df[column].clip(lower_limit, upper_limit)\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "\n",
    "columns_to_winsorize = ['creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium',]\n",
    "lower_percentile = 0\n",
    "upper_percentile = 90\n",
    "\n",
    "df = winsorize_percentiles(df, columns_to_winsorize, lower_percentile, upper_percentile)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec99c314",
   "metadata": {},
   "source": [
    "\n",
    "##Step 2 Train-Test splitting\n",
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f70875b-823c-46b4-90c6-85b4c5625988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#15.6.2023\n",
    "###################################################################################################################\n",
    "##Step 2 Train-Test splitting\n",
    "###################################################################################################################\n",
    "\n",
    "#Split the dataset into train and test\n",
    "#The stratificatin is made on the death_event\n",
    "test_ratio_split=0.3\n",
    "train_set,test_set=train_test_split(df, test_size=test_ratio_split, random_state=42, stratify=df['DEATH_EVENT'])\n",
    "\n",
    "X_train=train_set.drop(target_features,axis=1)\n",
    "y_train=train_set[target_features].copy()\n",
    "\n",
    "X_test=test_set.drop(target_features,axis=1)\n",
    "y_test=test_set[target_features].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f68ac3f",
   "metadata": {},
   "source": [
    "##Step 3 Preparing target feature (y) for survival analysis\n",
    "###################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "097cbe3f-fd1c-4818-9f8d-6ad44b77062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['DEATH_EVENT']=y_train['DEATH_EVENT'].astype(bool)\n",
    "y_test['DEATH_EVENT']=y_test['DEATH_EVENT'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78d102b3-3343-42a9-b35f-c3f08ae3c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.to_records(index=False)\n",
    "y_test=y_test.to_records(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac1c09a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>233000.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>286000.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>141.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>174000.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>208000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age anaemia  creatinine_phosphokinase diabetes  ejection_fraction  \\\n",
       "186  50.0       0                     582.0        0                 50   \n",
       "258  45.0       1                      66.0        1                 25   \n",
       "104  60.0       0                      53.0        0                 50   \n",
       "161  45.0       1                     130.0        0                 35   \n",
       "263  68.0       1                     157.0        1                 60   \n",
       "\n",
       "    high_blood_pressure  platelets  serum_creatinine  serum_sodium sex smoking  \n",
       "186                   0   153000.0               0.6         134.0   0       0  \n",
       "258                   0   233000.0               0.8         135.0   1       0  \n",
       "104                   1   286000.0               2.1         141.2   0       0  \n",
       "161                   0   174000.0               0.8         139.0   1       1  \n",
       "263                   0   208000.0               1.0         140.0   0       0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c569a3c",
   "metadata": {},
   "source": [
    "#Survival analysis with Kaplan_meier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ce952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#Survival analysis with Kaplan_meier\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "\n",
    "time, survival_prob, conf_int = kaplan_meier_estimator(\n",
    "    y_train[\"DEATH_EVENT\"],y_train[\"time\"], conf_type=\"log-log\"\n",
    ")\n",
    "plt.step(time, survival_prob, where=\"post\")\n",
    "plt.fill_between(time, conf_int[0], conf_int[1], alpha=0.25, step=\"post\")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"est. probability of death $\\hat{S}(t)$\")\n",
    "plt.xlabel(\"time $t$\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51b50531",
   "metadata": {},
   "source": [
    "#Applying Multivariate Survival Model with Cox\n",
    "\n",
    "Following the tutotial:https://scikit-survival.readthedocs.io/en/stable/user_guide/00-introduction.html#Survival-Data\n",
    "\n",
    "In it they apply OneHotEncoder before fitting. We dont apply the OneHotEncoder to our nominal feature becuase they are already coded as 0 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5586f9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                         2.592338e-02\n",
       "anaemia                     5.139590e-01\n",
       "creatinine_phosphokinase    2.349774e-04\n",
       "diabetes                    4.350312e-01\n",
       "ejection_fraction          -3.235228e-02\n",
       "high_blood_pressure         6.400944e-01\n",
       "platelets                   2.596889e-08\n",
       "serum_creatinine            1.351029e+00\n",
       "serum_sodium               -2.761064e-02\n",
       "sex                        -6.951699e-02\n",
       "smoking                     4.121610e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "\n",
    "set_config(display=\"text\")  # displays text representation of estimators\n",
    "estimator = CoxPHSurvivalAnalysis()\n",
    "estimator.fit(X_train, y_train)\n",
    "pd.Series(estimator.coef_, index=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef15ee5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log hazard ratio with MinMaxScaler:\n",
      " age                         1.425786\n",
      "anaemia                     0.513959\n",
      "creatinine_phosphokinase    0.277461\n",
      "diabetes                    0.435031\n",
      "ejection_fraction          -1.455853\n",
      "high_blood_pressure         0.640094\n",
      "platelets                   0.009076\n",
      "serum_creatinine            2.161646\n",
      "serum_sodium               -0.695788\n",
      "sex                        -0.069517\n",
      "smoking                     0.412161\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Using the MinMax scaler, in theory using cox is not needed to Scaling the numerical value\n",
    "set_config(display=\"text\")  # displays text representation of estimators\n",
    "X_train[numerical_feats]=MinMaxScaler().fit_transform(X_train[numerical_feats])\n",
    "estimator = CoxPHSurvivalAnalysis()\n",
    "estimator.fit(X_train, y_train)\n",
    "series=pd.Series(estimator.coef_, index=X_train.columns)\n",
    "print('Log hazard ratio with MinMaxScaler:\\n', series )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cd84a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.473408</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365951</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036416</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>0.594850</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>0.746495</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090617</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>0.426037</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.509091</td>\n",
       "      <td>1</td>\n",
       "      <td>0.113482</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523319</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age anaemia  creatinine_phosphokinase diabetes  ejection_fraction  \\\n",
       "186  0.181818       0                  0.473408        0           0.777778   \n",
       "258  0.090909       1                  0.036416        1           0.222222   \n",
       "104  0.363636       0                  0.025407        0           0.777778   \n",
       "161  0.090909       1                  0.090617        0           0.444444   \n",
       "263  0.509091       1                  0.113482        1           1.000000   \n",
       "\n",
       "    high_blood_pressure  platelets  serum_creatinine  serum_sodium sex smoking  \n",
       "186                   0   0.365951            0.0625      0.714286   0       0  \n",
       "258                   0   0.594850            0.1875      0.753968   1       0  \n",
       "104                   1   0.746495            1.0000      1.000000   0       0  \n",
       "161                   0   0.426037            0.1875      0.912698   1       1  \n",
       "263                   0   0.523319            0.3125      0.952381   0       0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the StandarScaler, in theory using cox is not needed to Scaling the numerical value\n",
    "set_config(display=\"text\")  # displays text representation of estimators\n",
    "X_train[numerical_feats]=StandardScaler().fit_transform(X_train[numerical_feats])\n",
    "estimator = CoxPHSurvivalAnalysis()\n",
    "estimator.fit(X_train, y_train)\n",
    "series=pd.Series(estimator.coef_, index=X_train.columns)\n",
    "print('Log hazard ratio with StandardScaler:\\n', series )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44611e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It seems that the approach with the reasonable approach is the one without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f919dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measuring the Performance of Survival Models\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "prediction = estimator.predict(X_train)\n",
    "result = concordance_index_censored(y_train[\"DEATH_EVENT\"],y_train[\"time\"], prediction)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection: Which Variable is Most Predictive?\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def fit_and_score_features(X, y):\n",
    "    n_features = X.shape[1]\n",
    "    scores = np.empty(n_features)\n",
    "    m = CoxPHSurvivalAnalysis()\n",
    "    for j in range(n_features):\n",
    "        Xj = X[:, j : j + 1]\n",
    "        m.fit(Xj, y)\n",
    "        scores[j] = m.score(Xj, y)\n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = fit_and_score_features(X_train.values, y_train)\n",
    "pd.Series(scores, index=X_train.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcefb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "feat_select=ColumnTransformer([('numeric_pipe',feature_select.Feature_Selector(strategy='wrapper_RFECV'),numerical_feats),\n",
    "                                    ('nominal_pipe',feature_select.Feature_Selector(strategy='wrapper_RFECV'),nominal_feats)\n",
    "                                ])\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"select\", feat_select),\n",
    "        (\"model\", CoxPHSurvivalAnalysis()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.get_params().keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35b2962c",
   "metadata": {},
   "source": [
    "##Step 5 Initializing model estimators\n",
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f70dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing models\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis, CoxnetSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis, ComponentwiseGradientBoostingSurvivalAnalysis\n",
    "from sksurv.ensemble import ExtraSurvivalTrees\n",
    "from sksurv.svm import FastSurvivalSVM\n",
    "\n",
    "random_state=42\n",
    "cox=CoxPHSurvivalAnalysis()\n",
    "cox_elastic_net = CoxnetSurvivalAnalysis(l1_ratio=0.9, alpha_min_ratio=0.01, fit_baseline_model=True)\n",
    "rsf = RandomSurvivalForest(n_estimators=100, min_samples_split=10, min_samples_leaf=15, n_jobs=-1, random_state=random_state)\n",
    "gboost = GradientBoostingSurvivalAnalysis(n_estimators=20, learning_rate=1.0, max_depth=1, random_state=random_state)\n",
    "gboost_wise = ComponentwiseGradientBoostingSurvivalAnalysis(n_estimators=40, learning_rate=1.0, random_state=random_state)\n",
    "extra=ExtraSurvivalTrees(n_estimators=100, min_samples_split=10, min_samples_leaf=15, n_jobs=-1, random_state=random_state)\n",
    "svm=FastSurvivalSVM(max_iter=1000, tol=1e-5, random_state=random_state)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7a2d03b",
   "metadata": {},
   "source": [
    "### Get the best model with an overall GridSearch throughout all the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05960e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the best model with an overall GridSearch throughout all the estimators\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import joblib\n",
    "\n",
    "\n",
    "param_grid = {'select__numeric_pipe__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                'select__numeric_pipe__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                'select__nominal_pipe__k_out_features':[*range(1,len_nominal _feats+1)],\n",
    "                'select__nominal_pipe__strategy':['filter_cat','filter_mutinf','wrapper_RFE'],\n",
    "                'model':[cox,cox_elastic_net,rsf,gboost,gboost_wise,extra,svm]\n",
    "            }\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "gcv = GridSearchCV(pipe, param_grid, cv=cv)\n",
    "gcv.fit(X_train, y_train)\n",
    "\n",
    "#Saving the model\n",
    "joblib.dump(gcv, r'GridSearchCV_results\\HF_survival\\gcv_survival.pkl', compress=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d696dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(gcv.cv_results_).sort_values(by=\"mean_test_score\", ascending=False)\n",
    "results.loc[:, ~results.columns.str.endswith(\"_time\")]\n",
    "results.to_excel(r'GridSearchCV_results\\HF_survival\\gcv_survival.xlsx', index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e43affa",
   "metadata": {},
   "source": [
    "### For loop for iterate the grid search over each of the model and thus calculate the different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loop for iterate the grid search over each of the model and thus calculate the different metrics\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import joblib\n",
    "\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_censored,\n",
    "    concordance_index_ipcw,\n",
    "    cumulative_dynamic_auc,\n",
    "    integrated_brier_score,\n",
    ")\n",
    "\n",
    "hf_times=np.arange(y_test['time'].min(), y_test['time'].max(), 10)\n",
    "\n",
    "columns_names=['model','params','c_index','c_index_ipcw','model_mean_auc','brier_score']\n",
    "test_results_rows=[]\n",
    "\n",
    "#for model in [cox,cox_elastic_net,rsf,gboost,gboost_wise,extra,svm]:\n",
    "for model in [gboost,extra]:\n",
    "    pipe = Pipeline([(\"select\", feat_select),(\"model\", model)])\n",
    "    model_name=str(model).split(\"(\", 1)[0]\n",
    "\n",
    "    param_grid = {'select__numeric_pipe__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                'select__numeric_pipe__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                'select__nominal_pipe__k_out_features':[*range(1,len_nominal_feats+1)],\n",
    "                'select__nominal_pipe__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "    }\n",
    "\n",
    "    # param_grid = {'select__numeric_pipe__k_out_features':[*range(1,3)],\n",
    "    #             'select__numeric_pipe__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "    #             'select__nominal_pipe__k_out_features':[*range(1,3)],\n",
    "    #             'select__nominal_pipe__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "    # }\n",
    "\n",
    "    cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    gcv = GridSearchCV(pipe, param_grid, cv=cv)\n",
    "    gcv.fit(X_train, y_train)\n",
    "\n",
    "    #Saving the model\n",
    "    joblib.dump(gcv, r'GridSearchCV_results\\HF_survival\\gcv_survival_'+model_name+'.pkl', compress=1)\n",
    "    #saving the grid search results\n",
    "    results = pd.DataFrame(gcv.cv_results_).sort_values(by=\"mean_test_score\", ascending=False)\n",
    "    results.loc[:, ~results.columns.str.endswith(\"_time\")]\n",
    "    results.to_excel(r'GridSearchCV_results\\HF_survival\\gcv_survival_'+model_name+'.xlsx', index=True)\n",
    "\n",
    "    pipe.set_params(**gcv.best_params_)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    risk_scores=pipe.predict(X_test)\n",
    "\n",
    "    #Calculating metric concordance_index_censored with the test set\n",
    "    c_index=concordance_index_censored(y_test[\"DEATH_EVENT\"], y_test[\"time\"], risk_scores)[0]\n",
    "\n",
    "    #Calculating metric cconcordance_index_ipcw\n",
    "    c_index_ipcw=concordance_index_ipcw(y_train,y_test,risk_scores)[0]\n",
    "\n",
    "    #Calculating metric cumulative_dynamic_auc\n",
    "    model_auc, model_mean_auc = cumulative_dynamic_auc(y_train, y_test, risk_scores, hf_times)\n",
    "\n",
    "    #Calcultating Brier score\n",
    "    if model_name!='FastSurvivalSVM':\n",
    "        survs = pipe.predict_survival_function(X_test)\n",
    "        preds = np.asarray([[fn(t) for t in hf_times] for fn in survs])\n",
    "        brier_score= integrated_brier_score(y_train, y_test, preds, hf_times)\n",
    "    else:\n",
    "        brier_score='NaN'\n",
    "\n",
    "    results={'model':model_name,\n",
    "            'params':pipe.get_params(),\n",
    "            'c_index':c_index,\n",
    "            'c_index_ipcw':c_index_ipcw,\n",
    "            'model_mean_auc':model_mean_auc,\n",
    "            'brier_score':brier_score}\n",
    "    \n",
    "    test_results_rows.append(results)\n",
    "    \n",
    "test_results=pd.DataFrame(test_results_rows)\n",
    "test_results.to_excel(r'GridSearchCV_results\\HF_survival\\test_results_.xlsx', index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d651ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "pipe_best = Pipeline(\n",
    "    [\n",
    "        (\"select\", feat_select),\n",
    "        (\"model\", extra),\n",
    "    ]\n",
    ")\n",
    "best_model=joblib.load('GridSearchCV_results\\HF_survival\\gcv_survival_ExtraSurvivalTrees.pkl')\n",
    "pipe_best.set_params(**best_model.best_params_)\n",
    "pipe_best.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_features = pipe_best.named_steps['select'].named_steps['numeric_pipe'].get_support()\n",
    "\n",
    "numeric_selector = pipe_best.named_steps['select'].transformers_[0][1]\n",
    "nominal_selector = pipe_best.named_steps['select'].transformers_[1][1]\n",
    "columns=numerical_feats+nominal_feats\n",
    "num_mask=numeric_selector.feat_sel.get_support()\n",
    "nom_mask=nominal_selector.feat_sel.get_support()\n",
    "columns_mask=np.concatenate((num_mask, nom_mask))\n",
    "filtered_columns = np.array(columns)[columns_mask]\n",
    "print('columns', filtered_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(final_estimator.coef_, index=X_train.columns[transformer.get_support()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "daff318e",
   "metadata": {},
   "source": [
    "### GridSearchCV with the ExtraTree with the best parameters given my the foor loop over the iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0303cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best model with GridSearchCV for extra tree is different from the one produced by the overall GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import joblib\n",
    "\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_censored,\n",
    "    concordance_index_ipcw,\n",
    "    cumulative_dynamic_auc,\n",
    "    integrated_brier_score,\n",
    ")\n",
    "\n",
    "hf_times=np.arange(y_test['time'].min(), y_test['time'].max(), 10)\n",
    "\n",
    "columns_names=['model','params','c_index','c_index_ipcw','model_mean_auc','brier_score']\n",
    "test_results_rows=[]\n",
    "\n",
    "#for model in [cox,cox_elastic_net,rsf,gboost,gboost_wise,extra,svm]:\n",
    "for model in [extra]:\n",
    "    pipeExtra = Pipeline([(\"select\", feat_select),(\"model\", model)])\n",
    "    model_name=str(model).split(\"(\", 1)[0]\n",
    "\n",
    "    param_grid = {'select__numeric_pipe__k_out_features':[4],\n",
    "                'select__numeric_pipe__strategy':['filter_mutinf'],\n",
    "                'select__nominal_pipe__k_out_features':[1],\n",
    "                'select__nominal_pipe__strategy':['filter_mutinf']\n",
    "    }\n",
    "\n",
    "    cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    gcv = GridSearchCV(pipeExtra, param_grid, cv=cv)\n",
    "    gcv.fit(X_train, y_train)\n",
    "\n",
    "    #Saving the model\n",
    "    joblib.dump(gcv, r'GridSearchCV_results\\HF_survival\\gcv_survival_'+model_name+'_bestC-Interpret.pkl', compress=1)\n",
    "    #saving the grid search results\n",
    "    results = pd.DataFrame(gcv.cv_results_).sort_values(by=\"mean_test_score\", ascending=False)\n",
    "    results.loc[:, ~results.columns.str.endswith(\"_time\")]\n",
    "    #results.to_excel(r'GridSearchCV_results\\HF_survival\\gcv_survival_'+model_name+'.xlsx', index=True)\n",
    "\n",
    "    pipeExtra.set_params(**gcv.best_params_)\n",
    "    pipeExtra.fit(X_train, y_train)\n",
    "    \n",
    "    risk_scores=pipeExtra.predict(X_test)\n",
    "\n",
    "    #Calculating metric concordance_index_censored with the test set\n",
    "    c_index=concordance_index_censored(y_test[\"DEATH_EVENT\"], y_test[\"time\"], risk_scores)[0]\n",
    "\n",
    "    #Calculating metric cconcordance_index_ipcw\n",
    "    c_index_ipcw=concordance_index_ipcw(y_train,y_test,risk_scores)[0]\n",
    "\n",
    "    #Calculating metric cumulative_dynamic_auc\n",
    "    model_auc, model_mean_auc = cumulative_dynamic_auc(y_train, y_test, risk_scores, hf_times)\n",
    "\n",
    "    #Calcultating Brier score\n",
    "    if model_name!='FastSurvivalSVM':\n",
    "        survs = pipeExtra.predict_survival_function(X_test)\n",
    "        preds = np.asarray([[fn(t) for t in hf_times] for fn in survs])\n",
    "        brier_score= integrated_brier_score(y_train, y_test, preds, hf_times)\n",
    "    else:\n",
    "        brier_score='NaN'\n",
    "\n",
    "    results={'model':model_name,\n",
    "            'params':pipeExtra.get_params(),\n",
    "            'c_index':c_index,\n",
    "            'c_index_ipcw':c_index_ipcw,\n",
    "            'model_mean_auc':model_mean_auc,\n",
    "            'brier_score':brier_score}\n",
    "    \n",
    "    test_results_rows.append(results)\n",
    "    \n",
    "test_results=pd.DataFrame(test_results_rows)\n",
    "#test_results.to_excel(r'GridSearchCV_results\\HF_survival\\test_results_.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d7b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the most important features of the ExtraTree fitted with the following params\n",
    "#{'select__nominal_pipe__k_out_features': 1, 'select__nominal_pipe__strategy': 'filter_mutinf', \n",
    "#'select__numeric_pipe__k_out_features': 4, 'select__numeric_pipe__strategy': 'filter_mutinf'}\n",
    "numeric_selector = pipeExtra.named_steps['select'].transformers_[0][1]\n",
    "nominal_selector = pipeExtra.named_steps['select'].transformers_[1][1]\n",
    "columns=numerical_feats+nominal_feats\n",
    "num_mask=numeric_selector.feat_sel.get_support()\n",
    "nom_mask=nominal_selector.feat_sel.get_support()\n",
    "columns_mask=np.concatenate((num_mask, nom_mask))\n",
    "filtered_columns = np.array(columns)[columns_mask]\n",
    "print('columns', filtered_columns)\n",
    "\n",
    "#The result is\n",
    "#columns ['creatinine_phosphokinase' 'ejection_fraction' 'serum_creatinine'\n",
    "# 'serum_sodium' 'diabetes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[filtered_columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a6d2c6e",
   "metadata": {},
   "source": [
    "#### Exploring the explainability analysis of ExtraTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd30d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore explainability with SHAP, fit the estimator with the resultant variables selection\n",
    "import shap\n",
    "filtered_columns=['creatinine_phosphokinase', 'ejection_fraction', 'serum_creatinine',\n",
    " 'serum_sodium', 'diabetes']\n",
    "X_train_feat_sel=X_train[filtered_columns]\n",
    "X_test_feat_sel=X_test[filtered_columns]\n",
    "\n",
    "extra.fit(X_train_feat_sel,y_train)\n",
    "#shap_values=shap.KernelExplainer(extra,X_train_feat_sel).shap_values(X_train_feat_sel)\n",
    "##ExtraSurvivalTree does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f08ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feat_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Employ SurvSHAP library\n",
    "surv_train=extra.predict_survival_function(X_train_feat_sel, return_array=True)\n",
    "surv_val=extra.predict_survival_function(X_train_feat_sel, return_array=True)\n",
    "surv_test=extra.predict_survival_function(X_test_feat_sel, return_array=True)\n",
    "event_times=extra.unique_times_\n",
    "\n",
    "#Prepare Data for Explanation\n",
    "xte_data = (X_train_feat_sel, y_train['time'], y_train['DEATH_EVENT'],\n",
    "            X_train_feat_sel, y_train['time'], y_train['DEATH_EVENT'],            \n",
    "            X_test_feat_sel, y_test['time'], y_test['DEATH_EVENT'])\n",
    "\n",
    "#Prepare the Survival Curves for Explanation\n",
    "survival_curves = (surv_train, surv_val, surv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687542a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = SurvSHAP(prefix_name='flchain_sub1_example', max_depth=15)\n",
    "explainer.fit(xte_data=xte_data, survival_curves=survival_curves, event_times=event_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_train = explainer.explain(x=X_train_feat_sel, features_names_list=filtered_columns, suffex='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de252ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 0\n",
    "feature_importnce_df = pd.DataFrame(zip(filtered_columns, np.abs(explainer.shap_values[pattern]).sum(axis=0)), columns=['Feature', 'Importance'])\n",
    "feature_importnce_df.set_index('Feature', inplace=True)\n",
    "\n",
    "plt.figure(figsize=(5, 2))\n",
    "feature_importnce_df.sort_values('Importance')['Importance'].plot.barh()\n",
    "plt.figure()\n",
    "shap.summary_plot(explainer.shap_values[pattern], X_train_feat_sel, feature_names=filtered_columns, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3bd638",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feat_sel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39138a91",
   "metadata": {},
   "source": [
    "### Exploring the best 10 results of every estimator we discover the most balanced c_index interpretability is gcv_survival_GradientBoostingSurvivalAnalysis with the params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2af65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring the best 10 results of every estimator we discover the most balanced c_index interpretability is \n",
    "#gcv_survival_GradientBoostingSurvivalAnalysis with the params\n",
    "#{'select__nominal_pipe__k_out_features': 2, 'select__nominal_pipe__strategy': 'filter_mutinf',\n",
    "# 'select__numeric_pipe__k_out_features': 2, 'select__numeric_pipe__strategy': 'filter_mutinf'}\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import joblib\n",
    "\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_censored,\n",
    "    concordance_index_ipcw,\n",
    "    cumulative_dynamic_auc,\n",
    "    integrated_brier_score,\n",
    ")\n",
    "\n",
    "hf_times=np.arange(y_test['time'].min(), y_test['time'].max(), 10)\n",
    "\n",
    "columns_names=['model','params','c_index','c_index_ipcw','model_mean_auc','brier_score']\n",
    "test_results_rows=[]\n",
    "\n",
    "#for model in [cox,cox_elastic_net,rsf,gboost,gboost_wise,extra,svm]:\n",
    "for model in [gboost]:\n",
    "    pipeGBoost = Pipeline([(\"select\", feat_select),(\"model\", model)])\n",
    "    model_name=str(model).split(\"(\", 1)[0]\n",
    "\n",
    "    param_grid = {'select__numeric_pipe__k_out_features':[2],\n",
    "                'select__numeric_pipe__strategy':['filter_mutinf'],\n",
    "                'select__nominal_pipe__k_out_features':[2],\n",
    "                'select__nominal_pipe__strategy':['filter_mutinf']\n",
    "    }\n",
    "\n",
    "    cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    gcv = GridSearchCV(pipeGBoost, param_grid, cv=cv)\n",
    "    gcv.fit(X_train, y_train)\n",
    "\n",
    "    #Saving the model\n",
    "    joblib.dump(gcv, r'GridSearchCV_results\\HF_survival\\gcv_survival_'+model_name+'_bestBalanced.pkl', compress=1)\n",
    "    #saving the grid search results\n",
    "    results_gcv = pd.DataFrame(gcv.cv_results_).sort_values(by=\"mean_test_score\", ascending=False)\n",
    "    results_gcv.loc[:, ~results_gcv.columns.str.endswith(\"_time\")]\n",
    "    results_gcv.to_excel(r'GridSearchCV_results\\HF_survival\\gcv_survival_'+model_name+'_bestBalanced.xlsx', index=True)\n",
    "\n",
    "    pipeGBoost.set_params(**gcv.best_params_)\n",
    "    pipeGBoost.fit(X_train, y_train)\n",
    "    \n",
    "    risk_scores=pipeGBoost.predict(X_test)\n",
    "\n",
    "    #Calculating metric concordance_index_censored with the test set\n",
    "    c_index=concordance_index_censored(y_test[\"DEATH_EVENT\"], y_test[\"time\"], risk_scores)[0]\n",
    "\n",
    "    #Calculating metric cconcordance_index_ipcw\n",
    "    c_index_ipcw=concordance_index_ipcw(y_train,y_test,risk_scores)[0]\n",
    "\n",
    "    #Calculating metric cumulative_dynamic_auc\n",
    "    model_auc, model_mean_auc = cumulative_dynamic_auc(y_train, y_test, risk_scores, hf_times)\n",
    "\n",
    "    #Calcultating Brier score\n",
    "    if model_name!='FastSurvivalSVM':\n",
    "        survs = pipeGBoost.predict_survival_function(X_test)\n",
    "        preds = np.asarray([[fn(t) for t in hf_times] for fn in survs])\n",
    "        brier_score= integrated_brier_score(y_train, y_test, preds, hf_times)\n",
    "    else:\n",
    "        brier_score='NaN'\n",
    "\n",
    "    results={'model':model_name,\n",
    "            'params':pipe.get_params(),\n",
    "            'c_index':c_index,\n",
    "            'c_index_ipcw':c_index_ipcw,\n",
    "            'model_mean_auc':model_mean_auc,\n",
    "            'brier_score':brier_score}\n",
    "    \n",
    "    test_results_rows.append(results)\n",
    "    \n",
    "test_results=pd.DataFrame(test_results_rows)\n",
    "test_results.to_excel(r'GridSearchCV_results\\HF_survival\\test_results_'+model_name+'_bestBalanced.xlsx', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd581d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the most important features of the ExtraTree fitted with the following params\n",
    "#{'select__nominal_pipe__k_out_features': 1, 'select__nominal_pipe__strategy': 'filter_mutinf', \n",
    "#'select__numeric_pipe__k_out_features': 4, 'select__numeric_pipe__strategy': 'filter_mutinf'}\n",
    "numeric_selector = pipeGBoost.named_steps['select'].transformers_[0][1]\n",
    "nominal_selector = pipeGBoost.named_steps['select'].transformers_[1][1]\n",
    "columns=numerical_feats+nominal_feats\n",
    "num_mask=numeric_selector.feat_sel.get_support()\n",
    "nom_mask=nominal_selector.feat_sel.get_support()\n",
    "columns_mask=np.concatenate((num_mask, nom_mask))\n",
    "filtered_columns = np.array(columns)[columns_mask]\n",
    "print('columns', filtered_columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab8c8461",
   "metadata": {},
   "source": [
    "#### Exploring the explainability analysis of GradientBoosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa224c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_columns=['ejection_fraction', 'serum_creatinine',\n",
    " 'anaemia', 'sex']\n",
    "X_train_feat_sel=X_train[filtered_columns]\n",
    "X_test_feat_sel=X_test[filtered_columns]\n",
    "\n",
    "gboost.fit(X_train_feat_sel,y_train)\n",
    "shap_values=shap.KernelExplainer(gboost,X_train_feat_sel).shap_values(X_train_feat_sel)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ada3531d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0006f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tutorial recommends to use concordance_index_ipcw\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_censored,\n",
    "    concordance_index_ipcw,\n",
    "    cumulative_dynamic_auc,\n",
    "    integrated_brier_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fac76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to evaluate the ROC at, due to the estimator’s dependence on inverse probability of censoring weighting. First, we are going to check whether the observed time of the test data lies within the observed time range of the training data\n",
    "y_events = y_train[y_train[\"DEATH_EVENT\"]]\n",
    "train_min, train_max = y_events[\"time\"].min(), y_events[\"time\"].max()\n",
    "\n",
    "y_events = y_test[y_test[\"DEATH_EVENT\"]]\n",
    "test_min, test_max = y_events[\"time\"].min(), y_events[\"time\"].max()\n",
    "\n",
    "assert (\n",
    "    train_min <= test_min < test_max < train_max\n",
    "), \"time range or test data is not within time range of training data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed837a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.percentile(y_train[\"time\"], np.linspace(5, 95, 15))\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_dynamic_auc(risk_score, label, color=None):\n",
    "    auc, mean_auc = cumulative_dynamic_auc(y_train, y_test, risk_score, times)\n",
    "\n",
    "    plt.plot(times, auc, marker=\"o\", color=color, label=label)\n",
    "    plt.xlabel(\"days from enrollment\")\n",
    "    plt.ylabel(\"time-dependent AUC\")\n",
    "    plt.axhline(mean_auc, color=color, linestyle=\"--\")\n",
    "    plt.legend()\n",
    "\n",
    "x_test_imputed=X_test.loc[:,numerical_feats]\n",
    "\n",
    "for i, col in enumerate(numerical_feats):\n",
    "    plot_cumulative_dynamic_auc(x_test_imputed[:, i], col, color=f\"C{i}\")\n",
    "    ret = concordance_index_ipcw(y_train, y_test, x_test_imputed[:, i], tau=times[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['time'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2478a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate a Model's prediction by using the cumulative dynamic auc\n",
    "\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "cox_ph=CoxPHSurvivalAnalysis()\n",
    "cox_ph.fit(X_train,y_train)\n",
    "\n",
    "hf_times=np.arange(7, 285, 10)\n",
    "\n",
    "cox_ph_risk_scores=cox_ph.predict(X_test)\n",
    "cox_ph_auc, cox_ph_mean_auc = cumulative_dynamic_auc(y_train, y_test, cox_ph_risk_scores, hf_times)\n",
    "\n",
    "plt.plot(hf_times, cox_ph_auc, marker=\"o\")\n",
    "plt.axhline(cox_ph_mean_auc, linestyle=\"--\")\n",
    "plt.xlabel(\"days of follow-up\")\n",
    "plt.ylabel(\"time-dependent AUC\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3866d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Time-dependent Risk Scores\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "\n",
    "rsf = RandomSurvivalForest(n_estimators=100, min_samples_leaf=7, random_state=0)\n",
    "rsf.fit(X_train, y_train)\n",
    "\n",
    "rsf_chf_funcs = rsf.predict_cumulative_hazard_function(X_test, return_array=False)\n",
    "rsf_risk_scores = np.row_stack([chf(hf_times) for chf in rsf_chf_funcs])\n",
    "\n",
    "rsf_auc, rsf_mean_auc = cumulative_dynamic_auc(y_train, y_test, rsf_risk_scores, hf_times)\n",
    "\n",
    "plt.plot(hf_times, cox_ph_auc, \"o-\", label=f\"CoxPH (mean AUC = {cox_ph_mean_auc:.3f})\")\n",
    "plt.plot(hf_times, rsf_auc, \"o-\", label=f\"RSF (mean AUC = {rsf_mean_auc:.3f})\")\n",
    "plt.xlabel(\"days from enrollment\")\n",
    "plt.ylabel(\"time-dependent AUC\")\n",
    "plt.legend(loc=\"lower center\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eaf6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time-dependent brier score\n",
    "score_cindex = pd.Series(\n",
    "    [\n",
    "        rsf.score(X_test, y_test),\n",
    "        cox_ph.score(X_test, y_test),\n",
    "        0.5,\n",
    "    ],\n",
    "    index=[\"RSF\", \"CPH\", \"Random\"],\n",
    "    name=\"c-index\",\n",
    ")\n",
    "\n",
    "score_cindex.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da907b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.functions import StepFunction\n",
    "\n",
    "rsf_surv_prob = np.row_stack([fn(hf_times) for fn in rsf.predict_survival_function(X_test)])\n",
    "cph_surv_prob = np.row_stack([fn(hf_times) for fn in cox_ph.predict_survival_function(X_test)])\n",
    "\n",
    "random_surv_prob = 0.5 * np.ones((y_test.shape[0], hf_times.shape[0]))\n",
    "\n",
    "km_func = StepFunction(*kaplan_meier_estimator(y_test[\"DEATH_EVENT\"], y_test[\"time\"]))\n",
    "km_surv_prob = np.tile(km_func(hf_times), (y_test.shape[0], 1))\n",
    "\n",
    "score_brier = pd.Series(\n",
    "    [\n",
    "        integrated_brier_score(y_train, y_test, prob, hf_times)\n",
    "        for prob in (rsf_surv_prob, cph_surv_prob, random_surv_prob, km_surv_prob)\n",
    "    ],\n",
    "    index=[\"RSF\", \"CPH\", \"Random\", \"Kaplan-Meier\"],\n",
    "    name=\"IBS\",\n",
    ")\n",
    "\n",
    "pd.concat((score_cindex, score_brier), axis=1).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c433016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Metrics in Hyper-parameter Search using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "from sksurv.metrics import (\n",
    "    as_concordance_index_ipcw_scorer,\n",
    "    as_cumulative_dynamic_auc_scorer,\n",
    "    as_integrated_brier_score_scorer,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec07c5b6",
   "metadata": {},
   "source": [
    "# Penalized Cox Models\n",
    "tutorial from https://scikit-survival.readthedocs.io/en/stable/user_guide/coxnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d0d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge penalization\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis, CoxnetSurvivalAnalysis\n",
    "\n",
    "cox_elastic_net = CoxnetSurvivalAnalysis(l1_ratio=0.9, alpha_min_ratio=0.01)\n",
    "cox_elastic_net.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55624ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing penaly strength alpha\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "coxnet_pipe = make_pipeline(StandardScaler(), CoxnetSurvivalAnalysis(l1_ratio=0.9, alpha_min_ratio=0.01, max_iter=100))\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FitFailedWarning)\n",
    "coxnet_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df07c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_alphas = coxnet_pipe.named_steps[\"coxnetsurvivalanalysis\"].alphas_\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "gcv = GridSearchCV(\n",
    "    make_pipeline(StandardScaler(), CoxnetSurvivalAnalysis(l1_ratio=0.9)),\n",
    "    param_grid={\"coxnetsurvivalanalysis__alphas\": [[v] for v in estimated_alphas]},\n",
    "    cv=cv,\n",
    "    error_score=0.5,\n",
    "    n_jobs=1,\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "cv_results = pd.DataFrame(gcv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b95337",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = cv_results.param_coxnetsurvivalanalysis__alphas.map(lambda x: x[0])\n",
    "mean = cv_results.mean_test_score\n",
    "std = cv_results.std_test_score\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "ax.plot(alphas, mean)\n",
    "ax.fill_between(alphas, mean - std, mean + std, alpha=0.15)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_ylabel(\"concordance index\")\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.axvline(gcv.best_params_[\"coxnetsurvivalanalysis__alphas\"][0], c=\"C1\")\n",
    "ax.axhline(0.5, color=\"grey\", linestyle=\"--\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb263088",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gcv.best_estimator_.named_steps[\"coxnetsurvivalanalysis\"]\n",
    "best_coefs = pd.DataFrame(best_model.coef_, index=X_train.columns, columns=[\"coefficient\"])\n",
    "\n",
    "non_zero = np.sum(best_coefs.iloc[:, 0] != 0)\n",
    "print(f\"Number of non-zero coefficients: {non_zero}\")\n",
    "\n",
    "non_zero_coefs = best_coefs.query(\"coefficient != 0\")\n",
    "coef_order = non_zero_coefs.abs().sort_values(\"coefficient\").index\n",
    "\n",
    "_, ax = plt.subplots(figsize=(6, 8))\n",
    "non_zero_coefs.loc[coef_order].plot.barh(ax=ax, legend=False)\n",
    "ax.set_xlabel(\"coefficient\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coxnet_pred = make_pipeline(StandardScaler(), CoxnetSurvivalAnalysis(l1_ratio=0.9, fit_baseline_model=True))\n",
    "coxnet_pred.set_params(**gcv.best_params_)\n",
    "coxnet_pred.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930cc835",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_fns = coxnet_pred.predict_survival_function(X_test)\n",
    "time_points = np.quantile(y_test[\"time\"], np.linspace(0, 0.6, 100))\n",
    "legend_handles = []\n",
    "legend_labels = []\n",
    "_, ax = plt.subplots(figsize=(9, 6))\n",
    "for fn, label in zip(surv_fns, X_test.loc[:, \"serum_creatinine\"].astype(int)):\n",
    "    (line,) = ax.step(time_points, fn(time_points), where=\"post\", color=f\"C{label}\", alpha=0.5)\n",
    "    \n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_ylabel(\"Survival probability\")\n",
    "ax.grid(True)\n",
    "#We dont know what this code is doing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc85487f",
   "metadata": {},
   "source": [
    "# Using Random Survival Forests\n",
    "Got from the tutorial https://scikit-survival.readthedocs.io/en/stable/user_guide/random-survival-forest.html\n",
    "\n",
    "Note: here the plot are a bit counter intuitive since the examples are trying to predict the survival and not the death event, i.e. the y column that handles the event is 'cens' instead of 'death'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14837387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "#y_train['DEATH_EVENT']=~y_train['DEATH_EVENT']\n",
    "random_state=20\n",
    "rsf = RandomSurvivalForest(\n",
    "    n_estimators=1000, min_samples_split=10, min_samples_leaf=15, n_jobs=-1, random_state=random_state)\n",
    "rsf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82149b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test['DEATH_EVENT']=~y_test['DEATH_EVENT']\n",
    "\n",
    "rsf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f060d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = rsf.predict_survival_function(X_test, return_array=True)\n",
    "\n",
    "for i, s in enumerate(surv):\n",
    "    plt.step(rsf.unique_times_, s, where=\"post\", label=str(i))\n",
    "plt.ylabel(\"Survival probability\")\n",
    "plt.xlabel(\"Time in days\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce1c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = rsf.predict_cumulative_hazard_function(X_test, return_array=True)\n",
    "\n",
    "for i, s in enumerate(surv):\n",
    "    plt.step(rsf.unique_times_, s, where=\"post\", label=str(i))\n",
    "plt.ylabel(\"Cumulative hazard\")\n",
    "plt.xlabel(\"Time in days\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(rsf, X_test, y_test, n_repeats=15, random_state=random_state)\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        k: result[k]\n",
    "        for k in (\n",
    "            \"importances_mean\",\n",
    "            \"importances_std\",\n",
    "        )\n",
    "    },\n",
    "    index=X_test.columns,\n",
    ").sort_values(by=\"importances_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosted Models\n",
    "From the tutorial in https://scikit-survival.readthedocs.io/en/stable/user_guide/boosting.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da2c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is recommended to use the GradientBoostingSurvivalAnalysis\n",
    "from sksurv.ensemble import ComponentwiseGradientBoostingSurvivalAnalysis\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "\n",
    "est_cph_tree = GradientBoostingSurvivalAnalysis(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "est_cph_tree.fit(X_train, y_train)\n",
    "cindex = est_cph_tree.score(X_test, y_test)\n",
    "print(round(cindex, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e79ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cph_tree = {}\n",
    "\n",
    "est_cph_tree = GradientBoostingSurvivalAnalysis(learning_rate=1.0, max_depth=1, random_state=0)\n",
    "for i in range(1, 31):\n",
    "    n_estimators = i * 5\n",
    "    est_cph_tree.set_params(n_estimators=n_estimators)\n",
    "    est_cph_tree.fit(X_train, y_train)\n",
    "    scores_cph_tree[n_estimators] = est_cph_tree.score(X_test, y_test)\n",
    "\n",
    "x, y = zip(*scores_cph_tree.items())\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"n_estimator\")\n",
    "plt.ylabel(\"concordance index\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cph_ls = {}\n",
    "\n",
    "est_cph_ls = ComponentwiseGradientBoostingSurvivalAnalysis(learning_rate=1.0, random_state=0)\n",
    "for i in range(1, 31):\n",
    "    n_estimators = i * 10\n",
    "    est_cph_ls.set_params(n_estimators=n_estimators)\n",
    "    est_cph_ls.fit(X_train, y_train)\n",
    "    scores_cph_ls[n_estimators] = est_cph_ls.score(X_test, y_test)\n",
    "\n",
    "x, y = zip(*scores_cph_ls.items())\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"n_estimator\")\n",
    "plt.ylabel(\"concordance index\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f52afb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(est_cph_ls.coef_, [\"Intercept\"] + X_train.columns.tolist())\n",
    "\n",
    "print(\"Number of non-zero coefficients:\", (coef != 0).sum())\n",
    "coef_nz = coef[coef != 0]\n",
    "coef_order = coef_nz.abs().sort_values(ascending=False).index\n",
    "coef_nz.loc[coef_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b6bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_aft_ls = ComponentwiseGradientBoostingSurvivalAnalysis(\n",
    "    loss=\"ipcwls\", n_estimators=300, learning_rate=1.0, random_state=0\n",
    ").fit(X_train, y_train)\n",
    "cindex = est_aft_ls.score(X_test, y_test)\n",
    "print(round(cindex, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99739112",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [i * 5 for i in range(1, 21)]\n",
    "\n",
    "estimators = {\n",
    "    \"no regularization\": GradientBoostingSurvivalAnalysis(learning_rate=1.0, max_depth=1, random_state=0),\n",
    "    \"learning rate\": GradientBoostingSurvivalAnalysis(learning_rate=0.1, max_depth=1, random_state=0),\n",
    "    \"dropout\": GradientBoostingSurvivalAnalysis(learning_rate=1.0, dropout_rate=0.1, max_depth=1, random_state=0),\n",
    "    \"subsample\": GradientBoostingSurvivalAnalysis(learning_rate=1.0, subsample=0.5, max_depth=1, random_state=0),\n",
    "}\n",
    "\n",
    "scores_reg = {k: [] for k in estimators.keys()}\n",
    "for n in n_estimators:\n",
    "    for name, est in estimators.items():\n",
    "        est.set_params(n_estimators=n)\n",
    "        est.fit(X_train, y_train)\n",
    "        cindex = est.score(X_test, y_test)\n",
    "        scores_reg[name].append(cindex)\n",
    "\n",
    "scores_reg = pd.DataFrame(scores_reg, index=n_estimators)\n",
    "\n",
    "ax = scores_reg.plot(xlabel=\"n_estimators\", ylabel=\"concordance index\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47fa1dba",
   "metadata": {},
   "source": [
    "# Introduction to Survival Support Vector Machine\n",
    "From guide: https://scikit-survival.readthedocs.io/en/stable/user_guide/survival-svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8195a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b402ac1-17b4-4170-ba7c-4362c5072773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "###################################################################################################################\n",
    "##Step 4 Building pipelines for data preparation\n",
    "###################################################################################################################\n",
    "\n",
    "#Lets define 3 pipeline mode\n",
    "#a) parallel approach where feature selection is performed in parallel \n",
    "# for numerical, nominal and categorical\n",
    "#b) general approach where feature selection is performed as a whole for other features\n",
    "#c) no feature selection is performed\n",
    "\n",
    "#Before a data preprocessing will take place for each type of feature\n",
    "pipeline_numeric_feat=Pipeline([ ('data_missing',missing_val_imput.Numeric_Imputer(strategy='median')),\n",
    "                                 ('scaler', MinMaxScaler())])\n",
    "\n",
    "pipeline_numeric_feat_mean=Pipeline([ ('data_missing',missing_val_imput.Numeric_Imputer(strategy='mean')),\n",
    "                                 ('scaler', MinMaxScaler())])\n",
    "\n",
    "pipeline_nominal_feat=Pipeline([('data_missing',missing_val_imput.Category_Imputer()),                                 \n",
    "                                 ('encoding', OrdinalEncoder())])#We dont use OneHotEncoder since it enlarges the number of nominal features \n",
    "\n",
    "pipeline_ordinal_feat=Pipeline([ ('data_missing',missing_val_imput.Category_Imputer(strategy='most_frequent')),\n",
    "                                 ('encoding', OrdinalEncoder())])\n",
    "\n",
    "\n",
    "#option a)\n",
    "pipe_numeric_featsel=Pipeline([('data_prep',pipeline_numeric_feat),\n",
    "                                ('feat_sel',feature_select.Feature_Selector(strategy='wrapper_RFECV') )])\n",
    "pipe_nominal_featsel=Pipeline([('data_prep',pipeline_nominal_feat),\n",
    "                                ('feat_sel',feature_select.Feature_Selector(strategy='wrapper_RFECV') )])\n",
    "pipe_ordinal_featsel=Pipeline([('data_prep',pipeline_ordinal_feat),\n",
    "                                ('feat_sel',feature_select.Feature_Selector(strategy='wrapper_RFECV') )])\n",
    "\n",
    "dataprep_pipe_opta=ColumnTransformer([('numeric_pipe',pipe_numeric_featsel,numerical_feats),\n",
    "                                    ('nominal_pipe',pipe_nominal_featsel,nominal_feats),\n",
    "                                    ('ordinal_pipe',pipe_ordinal_featsel,ordinal_feats)\n",
    "                                ])\n",
    "\n",
    "#option c)\n",
    "dataprep_merge_feat=ColumnTransformer([('numeric_pipe',pipeline_numeric_feat,numerical_feats),\n",
    "                                    ('nominal_pipe',pipeline_nominal_feat, nominal_feats),\n",
    "                                    ('ordinal_pipe',pipeline_ordinal_feat,ordinal_feats)\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2fd09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Init the estimator here\n",
    "cox=CoxPHSurvivalAnalysis()\n",
    "# survRF=\n",
    "# survGB=\n",
    "# survSVM=FastSurvivalSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71c9ea-37dc-4a16-8b68-c2675c4c41d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "##Step 7 Training the data set with GridSearchCV\n",
    "###################################################################################################################\n",
    "\n",
    "\n",
    "##7.a.1 Parallel approach\n",
    "###################################################################################################################\n",
    "full_parallel_pipe_opta=Pipeline([('data_prep',dataprep_pipe_opta),('est',cox)])\n",
    "full_parallel_pipe_opta.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88111a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not valid \n",
    "scoring = {\n",
    "    'c_index_censored': make_scorer(concordance_index_censored()),\n",
    "    'c_index_ipcw': make_scorer(concordance_index_ipcw),\n",
    "    'cd_auc': make_scorer(cumulative_dynamic_auc),\n",
    "    'brier_score': make_scorer(integrated_brier_score),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9068c4-f74d-4964-b77f-f5acf59cb3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Example to see the an individual fitting\n",
    "cox=CoxPHSurvivalAnalysis()\n",
    "full_parallel_pipe_opta=Pipeline([('data_prep',dataprep_pipe_opta),('clf',cox)])\n",
    "cox.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be732083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is needed to create different GridSearcCV for each of the metric considered\n",
    "\n",
    "\n",
    "\n",
    "gcv_cindex = GridSearchCV(\n",
    "    as_concordance_index_ipcw_scorer(cox, tau=y_train_time[-1]),\n",
    "    param_grid=cv_param_grid,\n",
    "    cv=cv,\n",
    "    n_jobs=4,\n",
    ").fit(gbsg_X, gbsg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c663a1-1b91-4242-bb40-5192bc737abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "#Step 8: Application of SCI-XAI per each type of survival analysis estimator\n",
    "###################################################################################################################\n",
    "\n",
    "#vcox_Cindex: Cox's proportional hazards model and concordance index ipcw as scorer\n",
    "cox=CoxPHSurvivalAnalysis()\n",
    "y_train_time=y_train['time']\n",
    "full_parallel_pipe_opta=Pipeline([('data_prep',dataprep_pipe_opta),('clf',cox)])\n",
    "##########################################################################################################################################\n",
    "#%%\n",
    "param_grid_vcox_Cindex_exp={\n",
    "            'data_prep__numeric_pipe__data_prep__data_missing__strategy':['mean','median'],\n",
    "                    'data_prep__numeric_pipe__feat_sel__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                    'data_prep__numeric_pipe__feat_sel__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                    'data_prep__nominal_pipe__feat_sel__k_out_features':[*range(1,len_nominal_feats+1)],\n",
    "                    'data_prep__nominal_pipe__feat_sel__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "                    }\n",
    "\n",
    "clf_vcox_exp_Cindex=GridSearchCV(as_concordance_index_ipcw_scorer(cox, tau=y_train_time[-1]),param_grid_vcox_Cindex_exp, cv=5,n_jobs=None)\n",
    "clf_vcox_exp_Cindex.fit(X_train,y_train)\n",
    "#%%\n",
    "print('Score of best estimator of clf_vDT_exp:', clf_vcox_exp.best_score_) #Score of best estimator of clf_vcox:0.8063281546040166\n",
    "\n",
    "#%%\n",
    "#Saving the results in an excel\n",
    "df_results_vDT_exp=pd.DataFrame(clf_vcox_exp.cv_results_)\n",
    "df_results_vDT_exp.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization_SurvAnalysis/df_results_vcox_exp.xlsx',index=False)\n",
    "#Saving the model\n",
    "joblib.dump(clf_vcox_exp, r'GridSearchCV_results/HF_case_fullpaper_winsorization_SurvAnalysis/clf_vcox_exp.pkl', compress=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51936575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#Obtaining restuls with the test set\n",
    "clf_vcox_exp.refit\n",
    "y_pred_vDT_exp = clf_vcox_exp.predict(X_test)\n",
    "\n",
    "test_results_DT={'clf':['clf_vDT_exp'],\n",
    "                 'params':[clf_vcox_exp.best_params_],\n",
    "                 'cindex_censored_test':[concordance_index_censored(y_test, y_pred_vDT_exp)],\n",
    "                 'balanced_accuracy_test':[balanced_accuracy_score(y_test, y_pred_vDT_exp)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_vDT_exp)],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_vDT_exp)],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_vDT_exp)],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_vDT_exp,pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_vDT_exp)]    \n",
    "    }\n",
    "#%%\n",
    "test_results_DT_paper=pd.DataFrame(data=test_results_DT)\n",
    "test_results_DT_paper.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/test_results_DT_paper.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25efbba2-725a-4ad1-ab11-11f55fa39d26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "#Step 8_notime: Application of SCI-XAI per each type of classifier\n",
    "###################################################################################################################\n",
    "\n",
    "#vDT:DecisionTree_notime\n",
    "##########################################################################################################################################\n",
    "#%%\n",
    "param_grid_vDT_exp={'clf':[dectree_clf],\n",
    "            'data_prep__numeric_pipe__data_prep__data_missing__strategy':['mean','median'],\n",
    "                    'data_prep__numeric_pipe__feat_sel__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                    'data_prep__numeric_pipe__feat_sel__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                    'data_prep__nominal_pipe__feat_sel__k_out_features':[*range(1,len_nominal_feats+1)],\n",
    "                    'data_prep__nominal_pipe__feat_sel__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "                    }\n",
    "\n",
    "clf_vDT_exp=GridSearchCV(full_parallel_pipe_opta_notime,param_grid_vDT_exp,scoring=scoring,refit='balanced_accuracy', cv=5,n_jobs=None)\n",
    "clf_vDT_exp.fit(X_train_notime,y_train)\n",
    "#%%\n",
    "print('Score of best estimator of clf_vDT_exp:', clf_vDT_exp.best_score_) #Score of best estimator of clf_vDT:0.8063281546040166\n",
    "\n",
    "#%%\n",
    "#Saving the results in an excel\n",
    "df_results_vDT_exp=pd.DataFrame(clf_vDT_exp.cv_results_)\n",
    "df_results_vDT_exp.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/df_results_vDT_exp_notime.xlsx',index=False)\n",
    "#Saving the model\n",
    "joblib.dump(clf_vDT_exp, r'GridSearchCV_results/HF_case_fullpaper_winsorization/clf_vDT_exp_notime.pkl', compress=1)\n",
    "\n",
    "#%%\n",
    "#Obtaining classification  with test set\n",
    "clf_vDT_exp.refit\n",
    "y_pred_vDT_exp = clf_vDT_exp.predict(X_test_notime)\n",
    "\n",
    "test_results_DT={'clf':['clf_vDT_exp'],\n",
    "                 'params':[clf_vDT_exp.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_vDT_exp)],\n",
    "                 'balanced_accuracy_test':[balanced_accuracy_score(y_test, y_pred_vDT_exp)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_vDT_exp)],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_vDT_exp)],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_vDT_exp)],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_vDT_exp,pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_vDT_exp)]    \n",
    "    }\n",
    "#%%\n",
    "test_results_DT_paper=pd.DataFrame(data=test_results_DT)\n",
    "test_results_DT_paper.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/test_results_DT_paper_notime.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f3243c-996f-4471-8925-c5a07e5b8336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vRF:Random Forest\n",
    "###################################################################################################################\n",
    "#%%\n",
    "param_grid_vRF_exp={'clf': [rndforest_clf],\n",
    "            'data_prep__numeric_pipe__data_prep__data_missing__strategy':['median'],\n",
    "                    'data_prep__numeric_pipe__feat_sel__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                    'data_prep__numeric_pipe__feat_sel__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                    'data_prep__nominal_pipe__feat_sel__k_out_features':[*range(1,len_nominal_feats+1)],\n",
    "                    'data_prep__nominal_pipe__feat_sel__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "     }\n",
    "\n",
    "clf_vRF_exp=GridSearchCV(full_parallel_pipe_opta,param_grid_vRF_exp,scoring=scoring,refit='balanced_accuracy', cv=5,n_jobs=None)\n",
    "clf_vRF_exp.fit(X_train,y_train)\n",
    "#%%\n",
    "print('Score of best estimator of clf_vRF_exp:', clf_vRF_exp.best_score_) #Score of best estimator of clf_vRF: 1\n",
    "\n",
    "#Saving the results in an excel\n",
    "df_results_vRF_exp=pd.DataFrame(clf_vRF_exp.cv_results_)\n",
    "df_results_vRF_exp.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/df_results_vRF_exp.xlsx',index=False)\n",
    "#Saving the model\n",
    "joblib.dump(clf_vRF_exp, r'GridSearchCV_results/HF_case_fullpaper_winsorization/clf_vRF_exp.pkl', compress=1)\n",
    "\n",
    "#%%\n",
    "#Obtaining classification  with test set\n",
    "clf_vRF_exp.refit\n",
    "y_pred_vRF_exp = clf_vRF_exp.predict(X_test)\n",
    "\n",
    "test_results_RF={'clf':['clf_vRF_exp'],\n",
    "                 'params':[clf_vRF_exp.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_vRF_exp)],\n",
    "                 'balanced_accuracy_test':[balanced_accuracy_score(y_test, y_pred_vRF_exp)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_vRF_exp)],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_vRF_exp)],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_vRF_exp)],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_vRF_exp,pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_vRF_exp)]    \n",
    "    }\n",
    "#%%\n",
    "test_results_RF_paper=pd.DataFrame(data=test_results_RF)\n",
    "test_results_RF_paper.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/test_results_RF_paper.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f37f51-fd16-4e12-a34c-c95f1a1dd867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vRF:Random Forest_notime\n",
    "###################################################################################################################\n",
    "#%%\n",
    "param_grid_vRF_exp={'clf': [rndforest_clf],\n",
    "            'data_prep__numeric_pipe__data_prep__data_missing__strategy':['median'],\n",
    "                    'data_prep__numeric_pipe__feat_sel__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                    'data_prep__numeric_pipe__feat_sel__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                    'data_prep__nominal_pipe__feat_sel__k_out_features':[*range(1,len_nominal_feats+1)],\n",
    "                    'data_prep__nominal_pipe__feat_sel__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "     }\n",
    "\n",
    "clf_vRF_exp=GridSearchCV(full_parallel_pipe_opta_notime,param_grid_vRF_exp,scoring=scoring,refit='balanced_accuracy', cv=5,n_jobs=None)\n",
    "clf_vRF_exp.fit(X_train_notime,y_train)\n",
    "#%%\n",
    "print('Score of best estimator of clf_vRF_exp:', clf_vRF_exp.best_score_) #Score of best estimator of clf_vRF: 1\n",
    "\n",
    "#Saving the results in an excel\n",
    "df_results_vRF_exp=pd.DataFrame(clf_vRF_exp.cv_results_)\n",
    "df_results_vRF_exp.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/df_results_vRF_exp_notime.xlsx',index=False)\n",
    "#Saving the model\n",
    "joblib.dump(clf_vRF_exp, r'GridSearchCV_results/HF_case_fullpaper_winsorization/clf_vRF_exp_notime.pkl', compress=1)\n",
    "\n",
    "#%%\n",
    "#Obtaining classification  with test set\n",
    "clf_vRF_exp.refit\n",
    "y_pred_vRF_exp = clf_vRF_exp.predict(X_test_notime)\n",
    "\n",
    "test_results_RF={'clf':['clf_vRF_exp'],\n",
    "                 'params':[clf_vRF_exp.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_vRF_exp)],\n",
    "                 'balanced_accuracy_test':[balanced_accuracy_score(y_test, y_pred_vRF_exp)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_vRF_exp)],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_vRF_exp)],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_vRF_exp)],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_vRF_exp,pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_vRF_exp)]    \n",
    "    }\n",
    "#%%\n",
    "test_results_RF_paper=pd.DataFrame(data=test_results_RF)\n",
    "test_results_RF_paper.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/test_results_RF_paper_notime.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f72ba4-0918-495d-b602-aead66256cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "#vET:Extra Trees\n",
    "###################################################################################################################\n",
    "#%%\n",
    "param_grid_vET_exp={'clf':[extratree_clf],\n",
    "            'data_prep__numeric_pipe__data_prep__data_missing__strategy':['mean','median'],\n",
    "                    'data_prep__numeric_pipe__feat_sel__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                    'data_prep__numeric_pipe__feat_sel__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                    'data_prep__nominal_pipe__feat_sel__k_out_features':[*range(1,len_nominal_feats+1)],\n",
    "                    'data_prep__nominal_pipe__feat_sel__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "                    }\n",
    "\n",
    "clf_vET_exp=GridSearchCV(full_parallel_pipe_opta,param_grid_vET_exp,scoring=scoring,refit='balanced_accuracy', cv=5,n_jobs=None)\n",
    "clf_vET_exp.fit(X_train,y_train)\n",
    "#%%\n",
    "print('Score of best estimator of clf_vET_exp:', clf_vET_exp.best_score_) #Score of best estimator of clf_vET:0.7623721106479727\n",
    "\n",
    "#%%\n",
    "#Saving the results in an excel\n",
    "df_results_vET_exp=pd.DataFrame(clf_vET_exp.cv_results_)\n",
    "df_results_vET_exp.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/df_results_vET_exp.xlsx',index=False)\n",
    "#Saving the model\n",
    "joblib.dump(clf_vET_exp, r'GridSearchCV_results/HF_case_fullpaper_winsorization/clf_vET_exp.pkl', compress=1)\n",
    "\n",
    "#%%\n",
    "#Obtaining classification  with test set\n",
    "clf_vET_exp.refit\n",
    "y_pred_vET_exp = clf_vET_exp.predict(X_test)\n",
    "\n",
    "test_results_ET={'clf':['clf_vET_exp'],\n",
    "                 'params':[clf_vET_exp.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_vET_exp)],\n",
    "                 'balanced_accuracy_test':[balanced_accuracy_score(y_test, y_pred_vET_exp)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_vET_exp)],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_vET_exp)],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_vET_exp)],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_vET_exp,pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_vET_exp)]    \n",
    "    }\n",
    "#%%\n",
    "test_results_ET_paper=pd.DataFrame(data=test_results_ET)\n",
    "test_results_ET_paper.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/test_results_ET_paper.xlsx',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be7f966-41e4-42c8-a2b1-662d2998fd4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "#vET:Extra Trees_notime\n",
    "###################################################################################################################\n",
    "#%%\n",
    "param_grid_vET_exp={'clf':[extratree_clf],\n",
    "            'data_prep__numeric_pipe__data_prep__data_missing__strategy':['mean','median'],\n",
    "                    'data_prep__numeric_pipe__feat_sel__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                    'data_prep__numeric_pipe__feat_sel__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                    'data_prep__nominal_pipe__feat_sel__k_out_features':[*range(1,len_nominal_feats+1)],\n",
    "                    'data_prep__nominal_pipe__feat_sel__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "                    }\n",
    "\n",
    "clf_vET_exp=GridSearchCV(full_parallel_pipe_opta_notime,param_grid_vET_exp,scoring=scoring,refit='balanced_accuracy', cv=5,n_jobs=None)\n",
    "clf_vET_exp.fit(X_train_notime,y_train)\n",
    "#%%\n",
    "print('Score of best estimator of clf_vET_exp:', clf_vET_exp.best_score_) #Score of best estimator of clf_vET:0.7623721106479727\n",
    "\n",
    "#%%\n",
    "#Saving the results in an excel\n",
    "df_results_vET_exp=pd.DataFrame(clf_vET_exp.cv_results_)\n",
    "df_results_vET_exp.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/df_results_vET_exp_notime.xlsx',index=False)\n",
    "#Saving the model\n",
    "joblib.dump(clf_vET_exp, r'GridSearchCV_results/HF_case_fullpaper_winsorization/clf_vET_exp_notime.pkl', compress=1)\n",
    "\n",
    "#%%\n",
    "#Obtaining classification  with test set\n",
    "clf_vET_exp.refit\n",
    "y_pred_vET_exp = clf_vET_exp.predict(X_test_notime)\n",
    "\n",
    "test_results_ET={'clf':['clf_vET_exp'],\n",
    "                 'params':[clf_vET_exp.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_vET_exp)],\n",
    "                 'balanced_accuracy_test':[balanced_accuracy_score(y_test, y_pred_vET_exp)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_vET_exp)],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_vET_exp)],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_vET_exp)],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_vET_exp,pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_vET_exp)]    \n",
    "    }\n",
    "#%%\n",
    "test_results_ET_paper=pd.DataFrame(data=test_results_ET)\n",
    "test_results_ET_paper.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/test_results_ET_paper_notime.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fcc975-396a-4f7e-b43d-56f0b2c32436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#vAB:AdaBoost\n",
    "###################################################################################################################\n",
    "#%%\n",
    "param_grid_vAB_exp={'clf':[ada_clf],\n",
    "            'data_prep__numeric_pipe__data_prep__data_missing__strategy':['mean','median'],\n",
    "                    'data_prep__numeric_pipe__feat_sel__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                    'data_prep__numeric_pipe__feat_sel__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                    'data_prep__nominal_pipe__feat_sel__k_out_features':[*range(1,len_nominal_feats+1)],\n",
    "                    'data_prep__nominal_pipe__feat_sel__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "                    }\n",
    "\n",
    "clf_vAB_exp=GridSearchCV(full_parallel_pipe_opta,param_grid_vAB_exp,scoring=scoring,refit='balanced_accuracy', cv=5,n_jobs=None)\n",
    "clf_vAB_exp.fit(X_train,y_train)\n",
    "#%%\n",
    "print('Score of best estimator of clf_vAB_exp:', clf_vAB_exp.best_score_) #Score of best estimator of clf_vAB:0.7623721106479727\n",
    "\n",
    "#%%\n",
    "#Saving the results in an excel\n",
    "df_results_vAB_exp=pd.DataFrame(clf_vAB_exp.cv_results_)\n",
    "df_results_vAB_exp.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/df_results_vAB_exp.xlsx',index=False)\n",
    "#Saving the model\n",
    "joblib.dump(clf_vAB_exp, r'GridSearchCV_results/HF_case_fullpaper_winsorization/clf_vAB_exp.pkl', compress=1)\n",
    "\n",
    "#%%\n",
    "#Obtaining classification  with test set\n",
    "clf_vAB_exp.refit\n",
    "y_pred_vAB_exp = clf_vAB_exp.predict(X_test)\n",
    "\n",
    "test_results_AB={'clf':['clf_vAB_exp'],\n",
    "                 'params':[clf_vAB_exp.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_vAB_exp)],\n",
    "                 'balanced_accuracy_test':[balanced_accuracy_score(y_test, y_pred_vAB_exp)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_vAB_exp)],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_vAB_exp)],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_vAB_exp)],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_vAB_exp,pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_vAB_exp)]    \n",
    "    }\n",
    "#%%\n",
    "test_results_AB_paper=pd.DataFrame(data=test_results_AB)\n",
    "test_results_AB_paper.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/test_results_AB_paper.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c0dd9-8663-45c4-b134-6b2885a15496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "#vAB:AdaBoost_notime\n",
    "###################################################################################################################\n",
    "#%%\n",
    "param_grid_vAB_exp={'clf':[ada_clf],\n",
    "            'data_prep__numeric_pipe__data_prep__data_missing__strategy':['mean','median'],\n",
    "                    'data_prep__numeric_pipe__feat_sel__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                    'data_prep__numeric_pipe__feat_sel__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                    'data_prep__nominal_pipe__feat_sel__k_out_features':[*range(1,len_nominal_feats+1)],\n",
    "                    'data_prep__nominal_pipe__feat_sel__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "                    }\n",
    "\n",
    "clf_vAB_exp=GridSearchCV(full_parallel_pipe_opta_notime,param_grid_vAB_exp,scoring=scoring,refit='balanced_accuracy', cv=5,n_jobs=None)\n",
    "clf_vAB_exp.fit(X_train_notime,y_train)\n",
    "#%%\n",
    "print('Score of best estimator of clf_vAB_exp:', clf_vAB_exp.best_score_) #Score of best estimator of clf_vAB:0.7623721106479727\n",
    "\n",
    "#%%\n",
    "#Saving the results in an excel\n",
    "df_results_vAB_exp=pd.DataFrame(clf_vAB_exp.cv_results_)\n",
    "df_results_vAB_exp.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/df_results_vAB_exp_notime.xlsx',index=False)\n",
    "#Saving the model\n",
    "joblib.dump(clf_vAB_exp, r'GridSearchCV_results/HF_case_fullpaper_winsorization/clf_vAB_exp_notime.pkl', compress=1)\n",
    "\n",
    "#%%\n",
    "#Obtaining classification  with test set\n",
    "clf_vAB_exp.refit\n",
    "y_pred_vAB_exp = clf_vAB_exp.predict(X_test_notime)\n",
    "\n",
    "test_results_AB={'clf':['clf_vAB_exp'],\n",
    "                 'params':[clf_vAB_exp.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_vAB_exp)],\n",
    "                 'balanced_accuracy_test':[balanced_accuracy_score(y_test, y_pred_vAB_exp)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_vAB_exp)],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_vAB_exp)],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_vAB_exp)],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_vAB_exp,pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_vAB_exp)]    \n",
    "    }\n",
    "#%%\n",
    "test_results_AB_paper=pd.DataFrame(data=test_results_AB)\n",
    "test_results_AB_paper.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/test_results_AB_paper_notime.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe83ded-0987-43fd-bef7-da8ee706af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#vGB:Gradient Boosting\n",
    "###################################################################################################################\n",
    "#%%\n",
    "param_grid_vGB_exp={'clf':[gradboost_clf],\n",
    "            'data_prep__numeric_pipe__data_prep__data_missing__strategy':['mean','median'],\n",
    "                    'data_prep__numeric_pipe__feat_sel__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                    'data_prep__numeric_pipe__feat_sel__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                    'data_prep__nominal_pipe__feat_sel__k_out_features':[*range(1,len_nominal_feats+1)],\n",
    "                    'data_prep__nominal_pipe__feat_sel__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "                    }\n",
    "\n",
    "clf_vGB_exp=GridSearchCV(full_parallel_pipe_opta,param_grid_vGB_exp,scoring=scoring,refit='balanced_accuracy', cv=5,n_jobs=None)\n",
    "clf_vGB_exp.fit(X_train,y_train)\n",
    "#%%\n",
    "print('Score of best estimator of clf_vGB_exp:', clf_vGB_exp.best_score_) #Score of best estimator of clf_vGB:0.7623721106479727\n",
    "\n",
    "#%%\n",
    "#Saving the results in an excel\n",
    "df_results_vGB_exp=pd.DataFrame(clf_vGB_exp.cv_results_)\n",
    "df_results_vGB_exp.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/df_results_vGB_exp.xlsx',index=False)\n",
    "#Saving the model\n",
    "joblib.dump(clf_vGB_exp, r'GridSearchCV_results/HF_case_fullpaper_winsorization/clf_vGB_exp.pkl', compress=1)\n",
    "\n",
    "#%%\n",
    "#Obtaining classification  with test set\n",
    "clf_vGB_exp.refit\n",
    "y_pred_vGB_exp = clf_vGB_exp.predict(X_test)\n",
    "\n",
    "test_results_GB={'clf':['clf_vGB_exp'],\n",
    "                 'params':[clf_vGB_exp.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_vGB_exp)],\n",
    "                 'balanced_accuracy_test':[balanced_accuracy_score(y_test, y_pred_vGB_exp)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_vGB_exp)],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_vGB_exp)],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_vGB_exp)],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_vGB_exp,pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_vGB_exp)]    \n",
    "    }\n",
    "#%%\n",
    "test_results_GB_paper=pd.DataFrame(data=test_results_GB)\n",
    "test_results_GB_paper.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/test_results_GB_paper.xlsx',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322666c-ac2c-40ac-9ff3-311955fe8b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#vGB:Gradient Boosting_notime\n",
    "###################################################################################################################\n",
    "#%%\n",
    "param_grid_vGB_exp={'clf':[gradboost_clf],\n",
    "            'data_prep__numeric_pipe__data_prep__data_missing__strategy':['mean','median'],\n",
    "                    'data_prep__numeric_pipe__feat_sel__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                    'data_prep__numeric_pipe__feat_sel__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                    'data_prep__nominal_pipe__feat_sel__k_out_features':[*range(1,len_nominal_feats+1)],\n",
    "                    'data_prep__nominal_pipe__feat_sel__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "                    }\n",
    "\n",
    "clf_vGB_exp=GridSearchCV(full_parallel_pipe_opta_notime,param_grid_vGB_exp,scoring=scoring,refit='balanced_accuracy', cv=5,n_jobs=None)\n",
    "clf_vGB_exp.fit(X_train_notime,y_train)\n",
    "#%%\n",
    "print('Score of best estimator of clf_vGB_exp:', clf_vGB_exp.best_score_) #Score of best estimator of clf_vGB:0.7623721106479727\n",
    "\n",
    "#%%\n",
    "#Saving the results in an excel\n",
    "df_results_vGB_exp=pd.DataFrame(clf_vGB_exp.cv_results_)\n",
    "df_results_vGB_exp.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/df_results_vGB_exp_notime.xlsx',index=False)\n",
    "#Saving the model\n",
    "joblib.dump(clf_vGB_exp, r'GridSearchCV_results/HF_case_fullpaper_winsorization/clf_vGB_exp_notime.pkl', compress=1)\n",
    "\n",
    "#%%\n",
    "#Obtaining classification  with test set\n",
    "clf_vGB_exp.refit\n",
    "y_pred_vGB_exp = clf_vGB_exp.predict(X_test_notime)\n",
    "\n",
    "test_results_GB={'clf':['clf_vGB_exp'],\n",
    "                 'params':[clf_vGB_exp.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_vGB_exp)],\n",
    "                 'balanced_accuracy_test':[balanced_accuracy_score(y_test, y_pred_vGB_exp)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_vGB_exp)],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_vGB_exp)],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_vGB_exp)],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_vGB_exp,pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_vGB_exp)]    \n",
    "    }\n",
    "#%%\n",
    "test_results_GB_paper=pd.DataFrame(data=test_results_GB)\n",
    "test_results_GB_paper.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/test_results_GB_paper_notime.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b402db2c-40a1-4a6b-98f8-ecc542f16437",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "#vXGB:eXtreme Gradient Boosting\n",
    "###################################################################################################################\n",
    "#%%\n",
    "param_grid_vXGB_exp={'clf':[xgboost_clf],\n",
    "            'data_prep__numeric_pipe__data_prep__data_missing__strategy':['mean','median'],\n",
    "                    'data_prep__numeric_pipe__feat_sel__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                    'data_prep__numeric_pipe__feat_sel__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                    'data_prep__nominal_pipe__feat_sel__k_out_features':[*range(1,len_nominal_feats+1)],\n",
    "                    'data_prep__nominal_pipe__feat_sel__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "                    }\n",
    "\n",
    "clf_vXGB_exp=GridSearchCV(full_parallel_pipe_opta,param_grid_vXGB_exp,scoring=scoring,refit='balanced_accuracy', cv=5,n_jobs=None)\n",
    "clf_vXGB_exp.fit(X_train,y_train)\n",
    "#%%\n",
    "print('Score of best estimator of clf_vXGB_exp:', clf_vXGB_exp.best_score_) #Score of best estimator of clf_vXGB:0.7623721106479727\n",
    "\n",
    "#%%\n",
    "#Saving the results in an excel\n",
    "df_results_vXGB_exp=pd.DataFrame(clf_vXGB_exp.cv_results_)\n",
    "df_results_vXGB_exp.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/df_results_vXGB_exp.xlsx',index=False)\n",
    "#Saving the model\n",
    "joblib.dump(clf_vXGB_exp, r'GridSearchCV_results/HF_case_fullpaper_winsorization/clf_vXGB_exp.pkl', compress=1)\n",
    "\n",
    "#%%\n",
    "#Obtaining classification  with test set\n",
    "clf_vXGB_exp.refit\n",
    "y_pred_vXGB_exp = clf_vXGB_exp.predict(X_test)\n",
    "\n",
    "test_results_XGB={'clf':['clf_vXGB_exp'],\n",
    "                 'params':[clf_vXGB_exp.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_vXGB_exp)],\n",
    "                 'balanced_accuracy_test':[balanced_accuracy_score(y_test, y_pred_vXGB_exp)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_vXGB_exp)],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_vXGB_exp)],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_vXGB_exp)],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_vXGB_exp,pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_vXGB_exp)]    \n",
    "    }\n",
    "#%%\n",
    "test_results_XGB_paper=pd.DataFrame(data=test_results_XGB)\n",
    "test_results_XGB_paper.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/est_results_XGB_paper.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0ccc2-ad6f-41fe-87a9-70a1ca1cf9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "#vXGB:eXtreme Gradient Boosting_notime\n",
    "###################################################################################################################\n",
    "#%%\n",
    "param_grid_vXGB_exp={'clf':[xgboost_clf],\n",
    "            'data_prep__numeric_pipe__data_prep__data_missing__strategy':['mean','median'],\n",
    "                    'data_prep__numeric_pipe__feat_sel__k_out_features':[*range(1,len_numerical_feats+1)],\n",
    "                    'data_prep__numeric_pipe__feat_sel__strategy':['filter_num','filter_mutinf','wrapper_RFE'],\n",
    "                    'data_prep__nominal_pipe__feat_sel__k_out_features':[*range(1,len_nominal_feats+1)],\n",
    "                    'data_prep__nominal_pipe__feat_sel__strategy':['filter_cat','filter_mutinf','wrapper_RFE']\n",
    "                    }\n",
    "\n",
    "clf_vXGB_exp=GridSearchCV(full_parallel_pipe_opta_notime,param_grid_vXGB_exp,scoring=scoring,refit='balanced_accuracy', cv=5,n_jobs=None)\n",
    "clf_vXGB_exp.fit(X_train_notime,y_train)\n",
    "#%%\n",
    "print('Score of best estimator of clf_vXGB_exp:', clf_vXGB_exp.best_score_) #Score of best estimator of clf_vXGB:0.7623721106479727\n",
    "\n",
    "#%%\n",
    "#Saving the results in an excel\n",
    "df_results_vXGB_exp=pd.DataFrame(clf_vXGB_exp.cv_results_)\n",
    "df_results_vXGB_exp.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/df_results_vXGB_exp_notime.xlsx',index=False)\n",
    "#Saving the model\n",
    "joblib.dump(clf_vXGB_exp, r'GridSearchCV_results/HF_case_fullpaper_winsorization/clf_vXGB_exp_notime.pkl', compress=1)\n",
    "\n",
    "#%%\n",
    "#Obtaining classification  with test set\n",
    "clf_vXGB_exp.refit\n",
    "y_pred_vXGB_exp = clf_vXGB_exp.predict(X_test_notime)\n",
    "\n",
    "test_results_XGB={'clf':['clf_vXGB_exp'],\n",
    "                 'params':[clf_vXGB_exp.best_params_],\n",
    "                 'accuracy_test':[accuracy_score(y_test, y_pred_vXGB_exp)],\n",
    "                 'balanced_accuracy_test':[balanced_accuracy_score(y_test, y_pred_vXGB_exp)],\n",
    "                 'f1_test':[f1_score(y_test, y_pred_vXGB_exp)],\n",
    "                 'precision_test':[precision_score(y_test, y_pred_vXGB_exp)],\n",
    "                 'recall_test':[recall_score(y_test, y_pred_vXGB_exp)],\n",
    "                 'specificity_test':[recall_score(y_test, y_pred_vXGB_exp,pos_label=0)],\n",
    "                 'roc_auc_test':[roc_auc_score(y_test, y_pred_vXGB_exp)]    \n",
    "    }\n",
    "#%%\n",
    "test_results_XGB_paper=pd.DataFrame(data=test_results_XGB)\n",
    "test_results_XGB_paper.to_excel(r'GridSearchCV_results/HF_case_fullpaper_winsorization/est_results_XGB_paper_notime.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de580095-215e-48a5-9487-4ad862490c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "xai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
